{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b3f6cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "bbd77d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'P', 1: 'i', 2: 'want', 3: 'a', 4: 'beer', 5: 'coke', 6: 'S', 7: 'E', 8: '.'}\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    ['ich mochte ein bier P','S i want a beer .','i want a beer . E'],\n",
    "    ['ich mochte ein cola P','S i want a coke . ','i want a coke . E']\n",
    "]\n",
    "src_vocab = {'P':0,'ich':1,'mochte':2,'ein':3,'bier':4,'cola':5}\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab = {'P':0,'i':1,'want':2,'a':3,'beer':4,'coke':5,'S':6,'E':7,'.':8}\n",
    "idx2word = {i:w for i,w in enumerate(tgt_vocab)}\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "print(idx2word)\n",
    "print(tgt_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "690ca1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ich mochte ein bier P', 'S i want a beer .', 'i want a beer . E'], ['ich mochte ein cola P', 'S i want a coke . ', 'i want a coke . E']]\n"
     ]
    }
   ],
   "source": [
    "src_len = 5 #enc_input max sequence length\n",
    "tgt_len = 6 #dec_input(=dec_output) max sequence length\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "aa6a5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(sentences):\n",
    "    enc_inputs,dec_inputs,dec_outputs = [],[],[]\n",
    "    enc_input,dec_input,dec_output = [],[],[]\n",
    "    for i in range(len(sentences)):\n",
    "        enc_input = [[src_vocab[n] for n in sentences[i][0].split()]] # [[1, 2, 3, 4, 0], [1, 2, 3, 5, 0]]\n",
    "        dec_input = [[tgt_vocab[n] for n in sentences[i][1].split()]] # [[6, 1, 2, 3, 4, 8], [6, 1, 2, 3, 5, 8]]\n",
    "        dec_output = [[tgt_vocab[n] for n in sentences[i][2].split()]] # [[1, 2, 3, 4, 8, 7], [1, 2, 3, 5, 8, 7]]\n",
    "      \n",
    "        enc_inputs.extend(enc_input)\n",
    "        dec_inputs.extend(dec_input)\n",
    "        dec_outputs.extend(dec_output)\n",
    "\n",
    "    return torch.LongTensor(enc_inputs),torch.LongTensor(dec_inputs),torch.LongTensor(dec_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "437f71f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 0],\n",
       "         [1, 2, 3, 5, 0]]),\n",
       " tensor([[6, 1, 2, 3, 4, 8],\n",
       "         [6, 1, 2, 3, 5, 8]]),\n",
       " tensor([[1, 2, 3, 4, 8, 7],\n",
       "         [1, 2, 3, 5, 8, 7]]))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_data(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "e97f3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs,dec_inputs,dec_outputs = make_data(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ec9aa624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self,enc_inputs,dec_inputs,dec_outputs):\n",
    "        super(MyDataSet,self).__init__()\n",
    "        self.enc_inputs = enc_inputs\n",
    "        self.dec_inputs = dec_inputs\n",
    "        self.dec_outputs = dec_outputs\n",
    "    def  __len__(self):\n",
    "        return self.enc_inputs.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        return self.enc_inputs[idx],self.dec_inputs[idx],self.dec_outputs[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "39844a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 5, 0]]), tensor([[6, 1, 2, 3, 4, 8],\n",
      "        [6, 1, 2, 3, 5, 8]]), tensor([[1, 2, 3, 4, 8, 7],\n",
      "        [1, 2, 3, 5, 8, 7]])]\n"
     ]
    }
   ],
   "source": [
    "loader = Data.DataLoader(MyDataSet(enc_inputs,dec_inputs,dec_outputs),2,True)\n",
    "for batch_data in loader:\n",
    "    print(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "736076bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "d_ff = 2048\n",
    "d_k =d_v =64\n",
    "n_layers = 6\n",
    "n_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5d62561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,dropout=0.1,max_len=5000):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len,d_model)\n",
    "        \n",
    "        \n",
    "        position = torch.arange(0,max_len,dtype=torch.float).unsqueeze(1)\n",
    "       \n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/d_model))\n",
    "       \n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0).transpose(0,1)\n",
    "        \n",
    "        self.register_buffer('pe',pe)\n",
    "    def forward(self,x):\n",
    "        x = x + self.pe[:x.size(0),:]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "7dd5d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "        pe = torch.zeros(10,512)\n",
    "        print(pe.size())\n",
    "        position = torch.arange(0,10,dtype=torch.float).unsqueeze(1)\n",
    "        print(position.size())\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float()*(-math.log(10000.0)/512))\n",
    "        print(div_term.size())\n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "        print(pe.size())#广播机制\n",
    "        pe = pe.unsqueeze(0).transpose(0,1)\n",
    "        print(pe.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f60df3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q,seq_k):\n",
    "    \"\"\"\n",
    "    seq_q:[batch_size,seq_len]\n",
    "    seq_k:[batch_size,seq_len]\n",
    "    seq_len:could be src_len or tgt_len\n",
    "    \"\"\"\n",
    "    batch_size,len_q = seq_q.size(0),seq_q.size(1)\n",
    "    batch_size,len_k = seq_k.size(0),seq_k.size(1)\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)\n",
    "    return pad_attn_mask.expand(batch_size,len_q,len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "72b35091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False, False]],\n",
      "\n",
      "        [[False, False, False]]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.randn(2,3)\n",
    "y = data.data.eq(0).unsqueeze(1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "0faa4a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequence_mask(seq):\n",
    "    \"\"\"\n",
    "    seq:[batch_size,tgt_len]\n",
    "    \"\"\"\n",
    "    attn_shape = [seq.size(0),seq.size(1),seq.size(1)]\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape),k=1)\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()#?bool()\n",
    "    return subsequence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "0c6a7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention,self).__init__()\n",
    "    def forward(self,Q,K,V,attn_mask):\n",
    "        \"\"\"\n",
    "        Q:[batch_size,n_heads,len_q,d_k]\n",
    "        K:[batch_size,n_heads,len_k,d_k]\n",
    "        V:[batch_size,n_heads,len_v(=len_k),d_v]\n",
    "        attn_mask:[batch_size,n_heads,seq_len,seq_len]\n",
    "        \"\"\"\n",
    "        scores = torch.matmul(Q,K.transpose(-1,-2))/np.sqrt(d_k)\n",
    "        #scores:[batch_size,n_heads,len_q,len_k]\n",
    "        scores.masked_fill_(attn_mask,-1e9)\n",
    "        #Fill elements of scores with 1e-9 where mask is true.\n",
    "        attn = torch.softmax(scores,dim=-1)\n",
    "        context = torch.matmul(attn,V)\n",
    "        #context:[batch_size,n_heads,len_q,d_v]\n",
    "        return context,attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "6c635290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model,d_k*n_heads,bias=False)\n",
    "        self.W_K = nn.Linear(d_model,d_k*n_heads,bias=False)\n",
    "        self.W_V = nn.Linear(d_model,d_v*n_heads,bias=False)\n",
    "        self.fc = nn.Linear(n_heads*d_v,d_model,bias=False)\n",
    "    def forward(self,input_Q,input_K,input_V,attn_mask):\n",
    "        \"\"\"\n",
    "        input_Q:[batch_size,len_q,d_model]\n",
    "        input_K:[batch_size,len_k,d_model]\n",
    "        input_V:[batch_size,len_v(=len_k),d_model]\n",
    "        attn_mask:[batch_size,n_heads,seq_len,seq_len]\n",
    "        \"\"\"\n",
    "        residual,batch_size = input_Q,input_Q.size(0)\n",
    "        \n",
    "        Q = self.W_Q(input_Q).view(batch_size,-1,n_heads,d_k).transpose(1,2)\n",
    "        K = self.W_K(input_K).view(batch_size,-1,n_heads,d_k).transpose(1,2)\n",
    "        V = self.W_V(input_V).view(batch_size,-1,n_heads,d_v).transpose(1,2)\n",
    "        #d_k(=d_q)?\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1,n_heads,1,1)\n",
    "        #attn_mask:[batch_size,n_heads,len_q,len_k] 第一个维度复制n_heads次\n",
    "        context,attn = ScaledDotProductAttention()(Q,K,V,attn_mask)\n",
    "        context = context.transpose(1,2).reshape(batch_size,-1,n_heads*d_v)\n",
    "        output = self.fc(context)\n",
    "        \n",
    "        return nn.LayerNorm(d_model)(output+residual),attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "fc592d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet,self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model,d_ff,bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff,d_model,bias=False)\n",
    "        )\n",
    "    def forward(self,inputs):\n",
    "        \"\"\"\n",
    "        inputs:[batch_size,seq_len,d_model]\n",
    "        \"\"\"\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(d_model)(output+residual)\n",
    "        #[batch_size,seq_len,d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "e1459d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "        \n",
    "    def forward(self,enc_inputs,enc_self_attn_mask):\n",
    "        \"\"\"\n",
    "        enc_inputs:[batch_size,src_len,d_model]\n",
    "        enc_self_attn_mask:[batch_size,src_len,src_len]\n",
    "        \"\"\"\n",
    "        enc_outputs,attn = self.enc_self_attn(enc_inputs,enc_inputs,enc_inputs,enc_self_attn_mask)\n",
    "        #enc_outputs:Z[batch_size,src_len,d_model]\n",
    "        #attn:softmax之后的[batch_size,src_len,src_len]\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "        return enc_outputs,attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "fb1b6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size,d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "    \n",
    "    def forward(self,enc_inputs):\n",
    "        \"\"\"\n",
    "        enc_inputs:[batch_size,src_Len]\n",
    "        \"\"\"\n",
    "        enc_outputs = self.src_emb(enc_inputs)\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0,1)).transpose(0,1)\n",
    "        #enc_outputs:[batch_size,src_len,d_model]\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs,enc_inputs)\n",
    "        #[batch_size,src_len,src_len]\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs,enc_self_attn = layer(enc_outputs,enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs,enc_self_attns\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "97357eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 4],\n",
      "        [0, 2, 1]])\n",
      "tensor([[[-0.2891,  2.4665,  0.1586,  0.5661,  0.6591],\n",
      "         [ 0.3609, -0.1599,  1.4397, -0.5303,  0.0638],\n",
      "         [ 0.3249, -0.2855, -0.8015,  0.2443,  0.4326]],\n",
      "\n",
      "        [[ 0.4750, -0.2368,  0.6460,  0.8659, -1.3432],\n",
      "         [-0.6435,  0.5105, -0.6344, -1.0465,  1.4007],\n",
      "         [-0.2891,  2.4665,  0.1586,  0.5661,  0.6591]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "x = torch.tensor([[1, 3, 4], [0, 2, 1]])  # 例子中的整数索引\n",
    "print(x)\n",
    "y = nn.Embedding(10, 5)\n",
    "output = y(x)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "a54eb2b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.dec_enc_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "    \n",
    "    def forward(self,dec_inputs,enc_outputs,dec_self_attn_mask,dec_enc_attn_mask):\n",
    "        \"\"\"\n",
    "        dec_inputs:[batch_size,tgt_len,d_model]\n",
    "        enc_outputs:[batch_size,src_len,d_model]\n",
    "        dec_self_attn_mask:[batch_size,tgt_len(Q),tgt_len(K)]\n",
    "        dec_enc_attn_mask:[batch_size,tgt_len(Q),src_len(K)]\n",
    "        \"\"\"\n",
    "        dec_outputs,dec_self_attn = self.dec_self_attn(dec_inputs,dec_inputs,dec_inputs,dec_self_attn_mask)\n",
    "        dec_outputs,dec_enc_attn = self.dec_enc_attn(dec_outputs,enc_outputs,enc_outputs,dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        \n",
    "        return dec_outputs,dec_self_attn,dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "e18ec5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size,d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "    \n",
    "    def forward(self,dec_inputs,enc_inputs,enc_outputs):\n",
    "        \"\"\"\n",
    "        dec_inputs:[batch_size,tgt_len]\n",
    "        enc_inputs:[batch_size,src_len]\n",
    "        enc_outputs:[batch_size,src_len,d_model]\n",
    "        \"\"\"\n",
    "        dec_outputs = self.tgt_emb(dec_inputs)#[batch_size,tgt_len,d_model]\n",
    "        dec_outputs = self.pos_emb(dec_outputs.transpose(0,1)).\\\n",
    "                      transpose(0,1) #[batch_size,tgt_len,d_model]\n",
    "        \n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs,dec_inputs)#[batch_size,tgt_len,tgt_len]\n",
    "        dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs)#[batch_size,tgt_len,tgt_len]\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask+dec_self_attn_subsequence_mask),0)\n",
    "        \n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_outputs,enc_inputs)#(Q,K)[batch_size,tgt_len,src_len]\n",
    "        \n",
    "        dec_self_attns,dec_enc_attns = [],[]\n",
    "        for layer in self.layers:\n",
    "            dec_outputs,dec_self_attn,dec_enc_attn = layer(dec_outputs,enc_outputs,dec_self_attn_mask,dec_enc_attn_mask)\n",
    "            #dec_outputs:[batch_size,tgt_len,d_model]\n",
    "            #dec_self_attn:[batch_size,n_heads,tgt_len,tgt_len]\n",
    "            #dec_enc_attn:[batch_size,tgt_len,src_len]\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "            #[torch.Size([batch_size,tgt_len,src_len]),torch.Size([batch_size,tgt_len,src_len]),...]\n",
    "        return dec_outputs,dec_self_attns,dec_enc_attns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "888304a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True, False, False],\n",
      "         [ True, False, False],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        [[False, False,  True],\n",
      "         [False, False,  True],\n",
      "         [False, False,  True]]])\n",
      "tensor([[[0, 1, 1],\n",
      "         [0, 0, 1],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [0, 0, 1],\n",
      "         [0, 0, 0]]], dtype=torch.uint8)\n",
      "tensor([[[ True,  True,  True],\n",
      "         [ True, False,  True],\n",
      "         [ True, False, False]],\n",
      "\n",
      "        [[False,  True,  True],\n",
      "         [False, False,  True],\n",
      "         [False, False,  True]]])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "dec_inputs = torch.tensor([[0,1,2],[2,4,0]])\n",
    "dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs,dec_inputs)\n",
    "print(dec_self_attn_pad_mask)\n",
    "dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs)\n",
    "print(dec_self_attn_subsequence_mask)\n",
    "dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask+dec_self_attn_subsequence_mask),0)\n",
    "print(dec_self_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "35f2b428",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.projection = nn.Linear(d_model,tgt_vocab_size,bias=False)\n",
    "        \n",
    "    def forward(self,enc_inputs,dec_inputs):\n",
    "        \"\"\"\n",
    "        enc_inputs:[batch_size,src_len]\n",
    "        dec_inputs:[batch_size,tgt_len]\n",
    "        \"\"\"\n",
    "        \n",
    "        enc_outputs,enc_self_attns = self.encoder(enc_inputs)\n",
    "        \n",
    "        dec_outputs,dec_self_attns,dec_enc_attns = self.decoder(dec_inputs,enc_inputs,enc_outputs)\n",
    "        \n",
    "        dec_logits = self.projection(dec_outputs)#[batch_size,tgt_len,tgt_vocab_size]\n",
    "        \n",
    "        return dec_logits.view(-1,dec_logits.size(-1)),enc_self_attns,dec_self_attns,dec_enc_attns\n",
    "        #dec_logits:[batch_size*tgt_len,tgt_vocab_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ee9d09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-3,momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "98ee2035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2488, -0.0254],\n",
      "        [-0.5280,  0.5660],\n",
      "        [-0.5183, -0.3582],\n",
      "        [ 0.5053,  0.6608]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1402, -0.2419, -0.1679,  0.2542], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.4977, 0.3949, 0.2427, 0.1168]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1020], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#test 参数形式  w1 b1 w2 b2\n",
    "# 定义一个简单的神经网络模型  \n",
    "class MyModel(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(MyModel, self).__init__()  \n",
    "        self.fc1 = nn.Linear(2, 4)  \n",
    "        self.fc2 = nn.Linear(4, 1)  \n",
    "  \n",
    "    def forward(self, x):  \n",
    "        x = self.fc1(x)  \n",
    "        x = self.fc2(x)  \n",
    "        return x  \n",
    "mode = MyModel()  \n",
    "# 获取模型的所有参数  \n",
    "pa = mode.parameters()  \n",
    "for p in pa:  \n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a18a2dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0001 loss =  2.221862\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0002 loss =  2.120991\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0003 loss =  1.910098\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0004 loss =  1.636849\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0005 loss =  1.429715\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0006 loss =  1.165649\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0007 loss =  0.979901\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0008 loss =  0.812619\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0009 loss =  0.678215\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0010 loss =  0.467947\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0011 loss =  0.391438\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0012 loss =  0.304238\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0013 loss =  0.244989\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0014 loss =  0.187953\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0015 loss =  0.188479\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0016 loss =  0.147264\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0017 loss =  0.102462\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0018 loss =  0.086887\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0019 loss =  0.073521\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0020 loss =  0.058300\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0021 loss =  0.062583\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0022 loss =  0.043484\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0023 loss =  0.035800\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0024 loss =  0.049329\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0025 loss =  0.048388\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0026 loss =  0.028071\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0027 loss =  0.029946\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0028 loss =  0.025184\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0029 loss =  0.018865\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([2, 6])\n",
      "torch.Size([12, 9])\n",
      "Epoch: 0030 loss =  0.017968\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for enc_inputs,dec_inputs,dec_outputs in loader:\n",
    "        \"\"\"\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        dec_outputs: [batch_size, tgt_len]\n",
    "        \"\"\"\n",
    "        print(enc_inputs.size())\n",
    "        print(dec_inputs.size())\n",
    "        print(dec_outputs.size())\n",
    "        outputs,enc_self_attns,dec_self_attns,dec_enc_attns = model(enc_inputs,dec_inputs)\n",
    "        #outputs:[batch_size*tgt_len,tgt_vocab_size]\n",
    "        print(outputs.size())\n",
    "        loss = criterion(outputs,dec_outputs.view(-1))\n",
    "        print('Epoch:','%04d'%(epoch+1),'loss = ','{:.6f}'.format(loss))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "e8630888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(5)\n",
      "tensor(8)\n",
      "tensor([1, 2, 3, 5, 0]) -> ['i', 'want', 'a', 'coke', '.']\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(8)\n",
      "tensor([1, 2, 3, 4, 0]) -> ['i', 'want', 'a', 'beer', '.']\n"
     ]
    }
   ],
   "source": [
    "def greedy_decoder(model, enc_input, start_symbol):\n",
    "    enc_outputs, enc_self_attns = model.encoder(enc_input)\n",
    "    dec_input = torch.zeros(1, 0).type_as(enc_input.data)\n",
    "    terminal = False\n",
    "    next_symbol = start_symbol\n",
    "    while not terminal:         \n",
    "        dec_input = torch.cat([dec_input.detach(),torch.tensor([[next_symbol]],dtype=enc_input.dtype)],-1)\n",
    "        dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)\n",
    "        projected = model.projection(dec_outputs)\n",
    "        prob = projected.squeeze(0).max(dim=-1, keepdim=False)[1]\n",
    "        next_word = prob.data[-1]\n",
    "        next_symbol = next_word\n",
    "        if next_symbol == tgt_vocab[\".\"]:\n",
    "            terminal = True\n",
    "        print(next_word)            \n",
    "    return dec_input\n",
    "\n",
    "# Test\n",
    "enc_inputs, _, _ = next(iter(loader))\n",
    "\n",
    "for i in range(len(enc_inputs)):\n",
    "    greedy_dec_input = greedy_decoder(model, enc_inputs[i].view(1, -1), start_symbol=tgt_vocab[\"S\"])\n",
    "    predict, _, _, _ = model(enc_inputs[i].view(1, -1), greedy_dec_input)\n",
    "    predict = predict.data.max(1, keepdim=True)[1]\n",
    "    print(enc_inputs[i], '->', [idx2word[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "7e7691a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cxy\\z_Demo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a534c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
